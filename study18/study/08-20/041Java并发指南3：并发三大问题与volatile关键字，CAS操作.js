先来看如下这个简单的Java类，该类中并没有使用任何的同步。
final class SetCheck {
	private int  a = 0;
	private long b = 0;
	void set() {
		a =  1;
		b = -1;
	}
	boolean check() {
		return ((b ==  0) ||(b == -1 && a == 1));
	}
}
'如果是在''一个串行执行的''语言中'，'执行SetCheck类中的''check方法''永远不会返回false'，
'即使编译器'，'运行时''和计算机硬件'并'没有按照''你所期望的逻辑'来'处理这段程序'，
'该方法''依然不会返回false'。
在程序执行过程中，下面这些你所不能预料的行为都是可能发生的：

'编译器''可能''会进行指令重排序'，'所以''b变量的赋值操作''可能先于a变量'。
如果是一个内联方法，'编译器可能'更甚一步'将该方法的指令与其他语句''进行重排序'。

'处理器可能'会'对语句所对应的机器指令''进行重排序之后再执行'，'甚至并发地去执行'。

'内存系统'（由高速缓存控制单元组成）'可能会对变量所对应的内存单元'的'写操作指令''进行重排序'。
'重排之后的写操作''可能会''对其他的计算/内存操作''造成覆盖'。

'编译器，处理器以及内存系统''可能会''让两条语句'的'机器指令交错'。
'比如在32位机器上'，'b变量的高位字节''先被写入'，
'然后是a变量'，'紧接着''才会是''b变量的低位字节'。

'编译器，处理器以及内存系统''可能会导致''代表两个变量的内存单元'在
（如果有的话）'连续的check调用'（如果有的话）'之后'的'某个时刻才更新'，
而以'这种方式保存相应的值'（如在CPU寄存器中）'仍会得到预期的结果'（check永远不会返回false）。

'在串行执行的语言中'，'只要程序执行''遵循类似串行的语义'，'如上几种行为''就不会有任何的影响'。
在'一段简单的代码块中'，'串行执行程序''不会依赖于代码的内部执行细节'，
因此'如上的几种行为''可以随意控制代码'。
'这样''就为编译器和计算机硬件''提供了基本的灵活性'。
基于此，在过去的数十年内很多技术（CPU的流水线操作，多级缓存，读写平衡，寄存器分配等等）
应运而生，为计算机处理速度的大幅提升奠定了基础。
这些操作的类似串行执行的特性可以让开发人员无须知道其内部发生了什么。
对于开发人员来说，如果不创建自己的线程，
那么这些行为也不会对其产生任何的影响。

然而'这些情况''在并发编程中''就完全不一样了'，'上面的代码''在并发过程中'，
'当一个线程''调用check方法的时候''完全有可能''另一个线程''正在执行set方法'，
'这种情况下''check方法'就'会将''上面提到的优化操作过程''暴露出来'。
如果上述'任意一个操作发生'，那么'check方法'就有'可能返回false'。
例'如'，'check方法读取long类型的变量b'的时候'可能得到的既不是0也不是-1'.
'而是一个''被写入一半的值'。
'另一种情况'，'set方法中的语句''的乱序执行''有可能导致check方法''读取变量b的值'的时候'是-1'，
'然而读取变量a时''却依然是0'。

换句话说，'不仅是并发执行''会导致问题'，'而且''在一些优化操作'（比如指令重排序）
'进行之后''也会导致''代码执行结果''和源代码中的逻辑有所出入'。
由于编译器和运行时技术的日趋成熟以及多处理器的逐渐普及，
这种现象就变得越来越普遍。
'对于'那些'一直从事串行编程背景''的开发人员'（其实，基本上所有的程序员）来说，
这可能'会导致令人诧异的结果'，而这些结果可能从没在串行编程中出现过。
这可能就是那些微妙难解的并发编程错误的根本源头吧。

在'绝大部分的情况下'，'有一个很简单易行的方法''来避免''那些在复杂的并发程序'
中因代码执行优化导致的问题：'使用同步'。
例如，如果SetCheck类中所有的方法都被声明为synchronized,
那么你就可以确保那么内部处理细节都不会影响代码预期的结果了。

但是在'有些情况下'你却'不能或者不想'去'使用同步'，
抑或着你需要推断别人未使用同步的代码。
在'这些情况下'你'只能依赖Java内存模型'所阐述的'结果语义'所提供'的最小保证'。
'Java内存模型''允许'上面提到的'所有操作'，'但是限制了它们'在'执行语义上潜在的结果'，
此外'还提出'了'一些技术让程序员'可以'用来控制这些语义''的某些方面'。

'Java内存模型'是Java语言规范的一部分，主要在JLS的第17章节介绍。
这里，'我们只是讨论''一些基本的''动机，属性以及模型的''程序一致性'。
这里对JLS第一版中所缺少的部分进行了澄清。

我们'假设Java内存模型''可以被看作'在1.2.4中描述的那种'标准的''SMP机器的''理想化模型'。

在'这个模型中'，'每一个线程'都'可以被看作'为'运行在不同的CPU上'，
然而'即使是''在多处理器上'，这种'情况也是很罕见的'。
但是'实际上'，通过'模型所具备的''某些特性'，
'这种CPU和线程单一映射''能够通过'一些'合理的方法去实现'。
例如，'因为CPU的寄存器''不能被''另一个CPU直接访问'，
'这种模型必须考虑到''某个线程无法得知''被另一个线程操作变量''的值的情况'。
'这种情况''不仅仅存在'于'多处理器环境上'，'在单核CPU环境里'，
'因为编译器和处理器'的'不可预测的行为'也'可能导致同样的情况'。

'Java内存模型''没有具体讲述''前面讨论的执行策略是由''编译器，'
'CPU，缓存控制器''还是其它机制促成的'。
'甚至没有用''开发人员所熟悉的''类，对象及方法来讨论。'
'取而代之'，'Java内存模型中''仅仅定义了线程和内存之间''那种抽象的关系'。
'众所周知'，'每个线程都拥有自己的''工作存储单元'（缓存和寄存器的抽象）
'来存储线程当前使用的''变量的值'。
'Java内存模型''仅仅保证了代码指令''与变量操作''的有序性'，
'大多数规则'都'只是指出''什么时候变量值''应该在内存''和线程工作内存之间''传输'。
'这些规则''主要是''为了解决''如下三个相互牵连的问题：'

'原子性'：'哪些指令''必须是''不可分割的'。'在Java内存模型中'，
'这些规则需声明''仅适用于'-—'实例变量和静态变量'，'也包括数组元素，'
'但不包括''方法中的局部变量'-—'的内存单元的简单读写操作'。

'可见性'：'在哪些情况下'，'一个线程执行的结果''对另一个线程是可见的'。
'这里需要关心的结果有'，'写入的字段''以及读取这个字段''所看到的值'。

'有序性'：'在什么情况下'，'某个线程的操作结果''对其它线程来看''是无序的'。
'最主要的乱序执行问题''主要表现在''读写操作和赋值语句的''相互执行顺序上'。

'原子性'
'当正确的使用了同步'，'上面属性都会具有''一个简单的特性'：
'一个同步方法''或者代码块中''所做的修改''对于使用了同一个锁的同步方法''或代码块'
'都具有原子性和可见性'。
'同步方法或代码块之间''的执行过程''都会和代码指定的执行顺序''保持一致'。
'即使代码块内部指令''也许是乱序执行的'，'也不会对使用了同步的''其它线程''造成任何影响'。

'当没有使用同步''或者使用的不一致的时候'，'情况就会变得复杂'。
'Java内存模型''所提供的保障''要比大多数开发人员''所期望的弱'，
'也远不及目前业界所实现的''任意一款''Java虚拟机'。
'这样'，'开发人员''就必须负起额外的义务''去保证对象的''一致性关系'：
'对象间''若有能被多个线程''看到的某种恒定关系'，'所有依赖这种关系的线程''就必须一直维持这种关系'，
而'不仅仅''由执行状态修改的线程''来维持'。

'除了long型字段''和double型字段外'，'java内存模型''确保访问任意类型字段''所对应的内存单元''都是原子的'。
'这包括''引用其它对象的''引用类型的字段'。此外，'volatile long' 和'volatile double''也具有原子性' 。
（'虽然java内存模型''不保证non-volatile long 和 non-volatile double''的原子性'，当然它们在某些场合也具有原子性。）
（译注：non-volatile long在64位JVM，OS，CPU下具有原子性）

'当在一个表达式中''使用一个''non-long或者non-double型字段时'，
'原子性可以确保''你将获得这个字段的初始值''或者某个线程对这个字段''写入之后的值'；
'但不会是两个或更多线程''在同一时间对这个字段''写入之后''产生混乱的结果值'

（'即原子性''可以确保'，'获取到的结果值'所'对应的所有bit位'，'全部都是''由单个线程写入的'）。
'但是'，'如下面'（译注：指可见性章节）'将要看到的'，
'原子性''不能确保''你获得的是任意线程''写入之后的''最新值'。 
'因此'，'原子性保证''通常对并发程序设计'的'影响很小'。

'可见性'

'只有在下列情况时'，'一个线程对字段的修改''才能确保''对另一个线程可见'：

'一个写线程释放一个锁之后'，'另一个读线程''随后获取了同一个锁'。
'本质上'，'线程释放锁时''会将强制刷新工作内存中的''脏数据''到主内存中'，
'获取一个锁''将强制线程装载'（或重新装载）'字段的值'。
'锁提供''对一个同步方法或块的''互斥性执行'，'线程执行''获取锁和释放锁时'，
'所有对字段的访问的内存效果''都是已定义的'。

'注意同步的''双重含义'：'锁提供高级同步协议'，'同时在线程执行同步方法或块时'，
'内存系统'（有时通过内存屏障指令）'保证值''的一致性'。
'这说明'，'与顺序程序设计''相比较'，'并发程序设计''与分布式程序设计''更加类似'。
'同步的第二个特性''可以视为一种机制'：
'一个线程''在运行已同步方法时'，它'将发送接收''其他线程''在同步方法中''对变量所做的修改'。
'从这一点来说'，'使用锁和发送消息''仅仅是语法不同而已'。

'如果把一个字段''声明为volatile型'，'线程''对这个字段写入后'，'在执行后续的内存访问之前'，
'线程必须刷新这个字段''且让这个字段''对其他线程可见'（即该字段立即刷新）。
'每次对volatile字段''的读访问'，'都要重新装载''字段的值'。

'一个线程''首次访问''一个对象的字段'，'它将读到''这个字段的''初始值或被某个线程写入后的值'。
'此外'，'把还未构造完成的对象的引用''暴露给某个线程'，'这是一个错误的做法' (see ?.1.2)。
'在构造函数内部''开始一个新线程''也是危险的'，'特别是这个类''可能被子类化时'。
'Thread.start''有如下的内存效果'：
'调用start方法的线程''释放了锁'，'随后开始执行的新线程''获取了这个锁'。
'如果在子类构造函数''执行之前'，'可运行的超类''调用了new Thread(this).start()'，
'当run方法执行时'，'对象很可能''还没有完全初始化'。
同样，'如果你创建且开始''一个新线程T'，'这个线程''使用了在执行start之后''才创建的一个对象X'。
'你不能确信X的字段值''将能对线程T可见'。'除非你把所有用到X的引用的方法''都同步'。
'如果可行的话'，'你可以在开始T线程之前''创建X'。

'线程终止时'，'所有写过的变量值''都要''刷新到主内存中'。
比如，'一个线程使用Thread.join'来'终止另一个线程'，
那么'第一个线程''肯定能看到''第二个线程对变量值得修改'。

注意，'在同一个线程的不同方法之间''传递对象的引用'，'永远也不会出现内存可见性问题'。
'内存模型''确保上述操作''最终会发生'，'一个线程''对一个特定字段的特定更新'，
'最终将会对其他线程''可见'，'但这个“最终”''可能是''很长一段时间'。
'线程之间没有同步时'，'很难保证''对字段的值''能在多线程之间''保持一致'
（'指写线程对字段的写入''立即能''对读线程可见'）。
'特别是'，'如果字段不是volatile''或没有通过同步来访问这个字段'，
'在一个循环中''等待其他线程对这个字段的写入'，'这种情况总是错误的'(see ?.2.6)。

'在缺乏同步的情况下'，'模型还允许不一致的''可见性'。
'比如，得到一个对象的一个字段''的最新值'，'同时得到这个对象的其他字段的''过期的值'。
'同样'，'可能读到一个引用变量的''最新值'，'但读取到这个引用变量引用的对象的字段的''过期值'。
不管怎样，'线程之间的可见性''并不总是失效'
（'指线程即使没有使用同步'，'仍然有可能''读取到字段的最新值'），
'内存模型''仅仅是''允许这种失效发生而已'。因此，'即使多个线程之间''没有使用同步'，
'也不保证''一定会发生''内存可见性问题'（指线程读取到过期的值），
'java内存模型''仅仅是允许''内存可见性问题发生而已'。
'在很多当前的JVM实现''和java执行平台中'，'甚至是在那些''使用多处理器的JVM和平台中'，
'也很少出现''内存可见性问题'。'共享同一个CPU的多个线程''使用公共的缓存'，'缺少强大的编译器优化'，
'以及存在强缓存一致性的硬件'，'这些都会使线程更新后的值'能够'立即在多线程之间传递'。
这'使得测试基于内存可见性的错误''是不切实际的'，因为'这样的错误极难发生'。
'或者这种错误'仅仅'在某个你没有使用过的平台上''发生'，'或仅在未来的某个平台上''发生'。
'这些类似的解释''对于多线程之间的内存可见性问题'来说'非常普遍'。
'没有同步的并发程序''会出现很多问题'，'包括内存一致性问题'。

有序性 

'有序性规则''表现在''以下两种场景': '线程内和线程间'

'从某个线程的角度''看方法的执行'，'指令会按照一种''叫“串行”（as-if-serial）的方式''执行'，
'此种方式'已经'应用于顺序编程语言'。
'这个线程''“观察”到其他线程''并发地执行非同步的代码时'，'任何代码''都有可能交叉执行'。
'唯一起作用的约束''是'：'对于同步方法'，'同步块以及volatile字段''的操作''仍维持相对有序'。
 
'再次提醒'，'这些''仅是最小特性''的规则'。
'具体到''任何一个程序或平台上'，'可能存在''更严格的''有序性规则'。
'所以你不能依赖它们'，'因为即使你的代码''遵循了这些更严格的规则'，
'仍可能在不同特性的JVM上''运行失败'，而且测试非常困难。

'需要注意的是'，'线程内部的观察视角''被JLS [1] 中''其他的语义的讨论''所采用'。
'例如'，'算术表达式的计算''在线程内看来''是从左到右地''执行操作'（JLS 15.6章节），
'而这种执行效果''是没有必要''被其他线程观察到的'。

'仅当某一时刻''只有一个线程操作变量时'，'线程内的执行''表现为串行'。
'出现上述情景'，'可能是因为''使用了同步'，'互斥体[2]' '或者纯属巧合'。
'当多线程''同时运行在''非同步的代码里''进行公用字段的读写'时，'会形成''一种执行模式'。
在'这种模式下'，'代码会任意''交叉执行'，'原子性和可见性''会失效'，以及'产生竞态条件'。
'这时线程执行''不再表现为串行'。

'尽管JLS列出了''一些特定的合法和非法的''重排序'，'如果碰到所列范围之外''的问题'，
'会降低''以下这条实践保证' ：
'运行结果''反映了''几乎所有的重排序''产生的代码交叉执行''的情况'。
'所以'，'没必要去探究这些代码的''有序性'。

'volatile关键字详解'：'在JMM中''volatile的内存语义''是锁'
'volatile的特性'
'当我们声明''共享变量''为volatile后'，'对这个变量的''读/写'将'会很特别'。
理解volatile特性的一个好方法是：
'把对volatile变量的''单个读/写'，'看成'是'使用同一个监视器锁''对这些单个读/写操作''做了同步'。
'下面我们通过具体的示例''来说明'，请看下面的示例代码：

class VolatileFeaturesExample {
    volatile long vl = 0L;  // 使用volatile声明64位的long型变量
 
    public void set(long l) {
        vl = l;   // 单个volatile变量的写
    }
 
    public void getAndIncrement () {
        vl++;    // 复合（多个）volatile变量的读/写
    }
 
 
    public long get() {
        return vl;   // 单个volatile变量的读
    }
}

'假设有多个线程''分别调用上面程序的''三个方法'，'这个程序''在语意上''和下面程序等价'：

class VolatileFeaturesExample {
    long vl = 0L;               // 64位的long型普通变量
 
    public synchronized void set(long l) {     对'单个'的'普通 变量'的'写''用'同一个'监视器同步'
        vl = l;
    }
 
    public void getAndIncrement () { // 普通方法调用
        long temp = get();           // 调用已同步的读方法
        temp += 1L;                  // 普通写操作
        set(temp);                   // 调用已同步的写方法
    }
    public synchronized long get() { 
        对'单个'的'普通变量'的'读''用'同一个'监视器同步'
        return vl;
    }
}
'如上面示例程序''所示'，'对一个volatile变量的''单个读/写操作'，
'与对一个普通变量的''读/写操作''使用同一个监视器锁''来同步'，'它们之间的执行效果''相同'。

'监视器锁'的happens-before规则'保证释放监视器''和获取监视器的''两个线程之间的内存可见性，
'这意味着''对一个volatile变量的读'，'总是能看到'（任意线程）'对这个volatile变量最后的写入'。

简而言之，'volatile变量''自身具有下列特性'：'监视器锁的语义''决定了临界区代码的执行''具有原子性'。
'这意味着''即使是64位的long型''和double型变量'，'只要它是volatile变量'，
'对该变量的读写''就将具有原子性'。
'如果是多个volatile操作''或类似于volatile++这种复合操作'，'这些操作整体上''不具有原子性'。

'可见性'。'对一个volatile变量的读'，'总是能看到'（任意线程）'对这个volatile变量''最后的写入'。

'原子性'：'对任意单个volatile变量''的读/写''具有原子性'，
'但类似于volatile++''这种复合操作''不具有原子性'。
'volatile写-读''建立的happens before关系'
'上面讲的是''volatile变量自身的特性'，'对程序员来说'，
'volatile对线程的内存可见性的影响''比volatile自身的特性''更为重要'，也更需要我们去关注。

从JSR-133开始，'volatile变量的写-读''可以实现''线程之间的通信'。

'从内存语义的角度来说'，'volatile与监视器锁''有相同的效果'：
'volatile写''和监视器的释放''有相同的内存语义'；
'volatile读''与监视器的获取''有相同的内存语义'。

请看下面使用volatile变量的示例代码：

class VolatileExample {
    int a = 0;
    volatile boolean flag = false;
 
    public void writer() {
        a = 1;                   // 1
        flag = true;               // 2
    }
 
    public void reader() {
        if (flag) {                // 3
            int i =  a;           // 4
            ……
        }
    }
}
'假设线程A''执行writer()方法之后'，'线程B''执行reader()方法'。
'根据happens before规则'，'这个过程建立的happens before 关系''可以分为两类'：

'根据程序次序规则'，'1 happens before 2'; '3 happens before 4'。
'根据volatile规则'，'2 happens before 3'。
'根据happens before的传递性规则'，'1 happens before 4'。
上述happens before 关系的图形化表现形式如下：

在上图中，'每一个箭头''链接的两个节点'，'代表了一个''happens before 关系'。
黑色箭头表示程序顺序规则；橙色箭头表示volatile规则；
蓝色箭头表示组合这些规则后提供的happens before保证。

这里'A线程''写一个volatile变量后'，'B线程''读同一个volatile变量'。
'A线程''在写volatile变量之前''所有可见的共享变量'，'在B线程''读同一个volatile变量后'，
'将立即变得对B线程可见'。

'volatile写-读''的内存语义'

'volatile写''的内存语义如下'：
'当写一个volatile变量时'，'JMM会把该线程对应的''本地内存中的''共享变量''刷新到主内存'。
以'上面示例程序''VolatileExample为例'，'假设线程A''首先执行writer()方法'，
'随后线程B''执行reader()方法'，'初始时两个线程的本地内存中的flag和a''都是初始状态'。
下图是线程A执行volatile写后，共享变量的状态示意图：

如上图所示，'线程A在写flag变量后'，
'本地内存A中''被线程A更新过的两个共享变量的值''被刷新到主内存中'。
此时，'本地内存A''和主内存中的共享变量的值是一致的'。

'volatile读''的内存语义如下'：

'当读一个volatile变量时'，'JMM'会'把该线程对应的本地内存''置为无效'。
'线程接下来''将从主内存中''读取共享变量'。
下面是线程B读同一个volatile变量后，共享变量的状态示意图：

如上图所示，'在读flag变量后'，'本地内存B已经被置为无效'。
此时，'线程B必须从主内存'中'读取共享变量'。
'线程B的读取操作''将导致本地内存B''与主内存中的共享变量的值'也'变成一致'的了。

'如果我们把''volatile写和volatile读''这两个步骤综合起来看的话'，
'在读线程B''读一个volatile变量后'，
'写线程A''在写这个volatile变量之前''所有可见的共享变量的值''都将立即变得对读线程B''可见'。

'下面对''volatile写和volatile读''的内存语义''做个总结'：

'线程A''写一个volatile变量'，
'实质上是线程A''向'接下来'将要读这个volatile变量的''某个线程''发出了'（其对共享变量所在修改的）'消息'。
'线程B读''一个volatile变量'，
'实质上是''线程B接收了''之前某个线程发出的'（在写这个volatile变量之前对共享变量所做修改的）'消息'。
'线程A''写一个volatile变量'，
随后'线程B''读这个volatile变量'，'这个过程''实质上是''线程A通过主内存''向线程B发送消息'。
'volatile内存语义''的实现'
下面，让'我们来看看JMM''如何实现volatile''写/读的''内存语义'。

前文我们提到过'重排序分为编译器重排序'和'处理器重排序'。
'为了实现volatile内存语义'，'JMM'会'分别限制'这'两种类型的重排序类型'。
下面是'JMM''针对编译器制定的volatile''重排序规则表'：
是否能重排序	第二个操作 
第一个操作 		'普通读/写' 'volatile读' 'volatile写'
'普通读/写'	 		 					   NO
'volatile读'	 NO			  NO		   NO
'volatile写' 				  NO		   NO

举例来说，'第三行''最后一个单元格'的'意思是'：
在'程序顺序中'，'当第一个操作''为普通变量'的'读或写时'，如果'第二个操作''为volatile写'，
则'编译器''不能''重排序'这两个操作。

从上表我们可以看出：
'当第二个操作''是volatile写'时，不管第一个操作是什么，'都不能重排序'。
这个规则'确保volatile写之前'的操作'不会被编译器重排序到volatile写之后'。
'当第一个操作''是volatile读'时，不管第二个操作是什么，'都不能重排序'。
这个规则'确保volatile读之后'的操作'不会被编译器重排序到volatile读之前'。
'当第一个操作''是volatile写'，'第二个操作是volatile读'时，'不能重排序'。
'为了实现volatile'的'内存语义'，'编译器'在'生成字节码时'，
'会在指令序列中''插入内存屏障'来'禁止特定类型'的'处理器重排序'。
对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，
为此，JMM采取保守策略。

下面是'基于保守策略的''JMM''内存屏障插入策略'：
在每个'volatile写'操作'的前面插入'一个'StoreStore屏障'。
在每个'volatile写'操作'的后面插入'一个'StoreLoad屏障'。
在每个'volatile读'操作'的前面插入'一个'LoadLoad屏障'。
在每个'volatile读'操作'的后面插入'一个'LoadStore屏障'。
上述内存屏障插入策略非常保守，但它'可以保证'在'任意处理器平台'，
'任意的程序'中都'能得到正确的volatile内存语义'。

下面是'保守策略下'，'volatile写''插入内存屏障后''生成的指令序列示意图'：

上图中的'StoreStore屏障'可以'保证在volatile写之前'，
'其前面的所有普通写操作''已经对任意处理器可见了'。
这是'因为StoreStore屏障'将'保障上面所有的普通写''在volatile写之前''刷新到主内存'。

这里比较有意思的是'volatile写后面的StoreLoad屏障'。
这个屏障的'作用是避免volatile写''与后面可能有的volatile读/写'操作'重排序'。
因为'编译器'常常'无法准确判断'在'一个volatile写的后面'，
'是否需要插入''一个StoreLoad屏障'（比如，'一个volatile写之后'方法'立即return'）。
为了保证能正确实现volatile的内存语义，'JMM在'这里'采取了保守策略'：
在'每个volatile写的后面''或在每个volatile读'的'前面''插入一个StoreLoad屏障'。
从整体执行效率的角度考虑，'JMM'选择了'在每个volatile写'的'后面插入一个StoreLoad屏障'。
因为'volatile写-读内存语义'的常见'使用模式是'：
'一个写线程写volatile变量'，'多个读线程读同一个volatile变量'。
'当读线程的数量'大大'超过写线程时'，
选择'在volatile写之后''插入StoreLoad屏障'将'带来可观的执行效率''的提升'。
从'这里'我们'可以看到JMM''在实现上的一个特点'：
'首先确保正确性'，然后'再去追求执行效率'。

下面是在保守策略下，'volatile读''插入内存屏障后''生成的指令序列示意图'：

上图中的'LoadLoad屏障''用来禁止处理器''把上面的volatile读''与下面的普通读''重排序'。
'LoadStore屏障''用来禁止处理器''把上面的volatile读''与下面的普通写''重排序'。

'上述volatile写'和'volatile读'的'内存屏障插入策略''非常保守'。
在'实际执行时'，'只要不改变volatile写-读的内存语义'，
'编译器可以根据具体情况''省略不必要的屏障'。
下面我们'通过具体的示例代码''来说明'：

class VolatileBarrierExample {
    int a;
    volatile int v1 = 1;
    volatile int v2 = 2;
 
    void readAndWrite() {
        int i = v1;		// 第一个volatile读
        int j = v2;		// 第二个volatile读
        a = i + j;		// 普通写
        v1 = i + 1;		// 第一个volatile写
        v2 = j * 2;		// 第二个 volatile写
    }

    …                    // 其他方法
}
针对'readAndWrite()方法'，'编译器在生成字节码时'可以'做如下的优化'：

注意，'最后的StoreLoad屏障不能省略'。'因为第二个volatile写之后'，'方法立即return'。
此时'编译器'可能'无法准确断定''后面是否会有volatile读或写'，'为了安全起见'，
'编译器'常常'会在这里插入一个StoreLoad屏障'。

上面的优化是针对任意处理器平台，由于不同的处理器有不同“松紧度”的处理器内存模型，
内存屏障的插入还可以根据具体的处理器内存模型继续优化。
以x86处理器为例，上图中除最后的StoreLoad屏障外，其它的屏障都会被省略。

前面保守策略下的volatile读和写，在 x86处理器平台可以优化成：

前文提到过，x86处理器仅会对写-读操作做重排序。X86不会对读-读，
读-写和写-写操作做重排序，因此在x86处理器中会省略掉这三种操作类型对应的内存屏障。
'在x86中'，'JMM仅需在volatile写后面''插入一个StoreLoad屏障''即可正确实现volatile写-读的内存语义'。
这意味着'在x86处理器中'，'volatile写的开销''比volatile读的开销'会'大很多'
（因为执行StoreLoad屏障开销会比较大）。

'JSR-133''为什么要增强volatile的内存语义'
在'JSR-133之前的旧Java内存模型中'，虽然'不允许''volatile变量'之间'重排序'，
'但旧的Java内存模型''允许volatile变量与普通变量之间''重排序'。
在旧的内存模型中，VolatileExample示例程序可能被重排序成下列时序来执行：

'在旧的内存模型中'，'当1和2'之间'没有数据依赖关系'时，'1和2之间''就可能被重排序'（3和4类似）。
其结果就是：读线程B执行4时，不一定能看到写线程A在执行1时对共享变量的修改。

因此'在旧的内存模型中' ，volatile的写-读没有监视器的释放-获所具有的内存语义。
为了'提供一种''比监视器锁''更轻量级的线程之间通信的机制'，
JSR-133专家组决定增强volatile的内存语义：
严格限制编译器和处理器对volatile变量与普通变量的重排序，
确保volatile的写-读和监视器的释放-获取一样，具有相同的内存语义。
从编译器重排序规则和处理器内存屏障插入策略来看，
只要volatile变量与普通变量之间的重排序可能会破坏volatile的内存语意，
这种重排序就会被编译器重排序规则和处理器内存屏障插入策略禁止。

'由于volatile''仅仅保证对单个volatile变量'的'读/写具有原子性'，
而'监视器锁的互斥执行'的特性'可以确保对整个临界区代码''的执行具有原子性'。
'在功能上'，'监视器锁比volatile更强大'；在可伸缩性和执行性能上，volatile更有优势。
如果读者想在程序中用volatile代替监视器锁，请一定谨慎。



'CAS操作详解'
本文属于作者原创，原文发表于InfoQ：http:// www.infoq.com/cn/articles/atomic-operation

1 引言
'原子'（atom）'本意是'“'不能被进一步分割'的'最小粒子'”，
而原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。
在多处理器上实现原子操作就变得有点复杂。
本文让我们一起来聊一聊在Inter处理器和Java里是如何实现原子操作的。

2 术语定义
术语名称		英文			解释
缓存行			Cache line	
缓存的最小操作单位

'比较并交换'		'Compare and Swap'	
'CAS操作''需要输入两个数值'，一个旧值（期望操作前的值）和一个新值，
在'操作期间先比较下'在'旧值有没有发生变化'，如果'没有发生变化'，'才交换成新值'，
'发生了变化则不交换'。

CPU流水线		CPU pipeline	
CPU流水线的工作方式就象工业生产上的装配流水线，
在CPU中由5~6个不同功能的电路单元组成一条指令处理流水线，
然后将一条X86指令分成5~6步后再由这些电路单元分别执行，
这样就能实现在一个CPU时钟周期完成一条指令，因此提高CPU的运算速度。

内存顺序冲突	Memory order violation	
内存顺序冲突一般是由假共享引起，
'假共享'是'指多个CPU同时修改同一个缓存行''的不同部分''而引起其中一个CPU的操作无效'，
当出现这个内存顺序冲突时，CPU必须清空流水线。

3 处理器如何实现原子操作
32位IA-32处理器使用'基于对缓存加锁''或总线加锁的方式'来'实现多处理器'之间的'原子操作'。

3.1 处理器自动'保证基本内存操作的原子性'
首先处理器会自动保证基本的内存操作的原子性。
处理器'保证从系统内存'当中'读取或者写入''一个字节''是原子的'，
意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。
奔腾6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，
但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度，
跨多个缓存行，跨页表的访问。
但是处理器'提供总线锁定'和'缓存锁定'两个机制来'保证复杂内存操作的''原子性'。

3.2 使用总线锁保证原子性
第一个机制是'通过总线锁保证原子性'。
如果'多个处理器同时对共享变量''进行读改写'（i++就是经典的读改写操作）'操作'，
那么'共享变量就会被多个处理器''同时进行操作'，'这样读改写操作就不是原子的'，
'操作完之后共享变量的值'会'和期望的不一致'，举个例子：
如果i=1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2。

原因是有'可能多个处理器'同时'从各自的缓存中''读取变量i'，
分别进行加一操作，然后分别写入系统内存当中。
那么'想要保证读改写共享变量'的'操作是原子的'，就'必须保证CPU1''读改写'共享变量'的时候'，
'CPU2不能操作缓存'了该共享变量内存地址的缓存。

处理器使用总线锁就是来解决这个问题的。所谓'总线锁'就是'使用'处理器提供的一个'LOCK＃信号'，
'当一个处理器'在总线上'输出此信号时'，'其他处理器'的请求将'被阻塞住',
那么'该处理器'可以'独占'使用'共享内存'。

3.3 使用缓存锁保证原子性
第二个机制是'通过缓存锁定保证原子性'。
在同一时刻我们只需保证对某个内存地址的操作是原子性即可，
但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，
其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，
最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。

'频繁使用的内存'会'缓存在处理器'的'L1，L2和L3高速缓存里'，
那么'原子操作'就'可以直接在处理器''内部缓存中进行'，并不需要声明总线锁，
在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。
所谓“'缓存锁定'”就是'如果缓存在处理器缓存行中,''内存区域'在LOCK操作期间'被锁定'，
'当它'执行锁操作'回写内存时'，'处理器''不在总线上声言''LOCK＃信号'，
'而是修改内部的内存地址'，并'允许它的缓存一致性机制'来'保证操作的原子性'，
因为'缓存一致性机制''会阻止同时修改''被两个以上处理器''缓存的内存区域数据'，
'当其他处理器''回写已被锁定的缓存行'的数据时会起缓存行无效，在例1中，
当CPU1修改缓存行中的i时使用缓存锁定，那么CPU2就不能同时缓存了i的缓存行。

但是有'两种情况'下'处理器不会使用缓存锁定'。
第一种情况是：
'当操作的数据''不能被缓存在''处理器内部'，'或操作的数据''跨多个缓存行'（cache line），
则'处理器会调用总线锁定'。
第二种情况是：
有些'处理器不支持缓存锁定'。对于Inter486和奔腾处理器,
就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。

以上两个机制我们可以通过Inter处理器提供了很多LOCK前缀的指令来实现。
比如位测试和修改指令BTS，BTR，BTC，交换指令XADD，CMPXCHG和其他一些操作数和逻辑指令，
比如ADD（加），OR（或）等，被这些指令操作的内存区域就会加锁，
导致其他处理器不能同时访问它。

4 'JAVA如何实现原子操作'
在'java'中'可以通过''锁和循环CAS'的方式'来实现原子操作'。

4.1 使用循环CAS实现原子操作
'JVM中的CAS操作'正是'利用了'上一节中提到的'处理器提供的CMPXCHG指令实现的'。
'自旋CAS'实现的'基本思路'就'是循环进行CAS操作''直到成功为止'，
以下代码实现了一个'基于CAS线程安全'的'计数器方法safeCount''和一个非线程安全的计数器count'。

public class Counter {
	private AtomicInteger atomicI = new AtomicInteger(0);
	private int i = 0;
	public static void main(String[] args) {
		final Counter cas = new Counter();
		List<Thread> ts = new ArrayList<Thread>(600);
		long start = System.currentTimeMillis();
		for (int j = 0; j < 100; j++) {
			Thread t = new Thread(new Runnable() {
				@Override
				public void run() {
					for (int i = 0; i < 10000; i++) {
						cas.count();
						cas.safeCount();
					}
				}
			});
			ts.add(t);
		}

		for (Thread t : ts) {
			t.start();
		}
		// 等待所有线程执行完成
		for (Thread t : ts) {
			try {
				t.join();
			} catch (InterruptedException e) {
				e.printStackTrace();
			}
		}

		System.out.println(cas.i);
		System.out.println(cas.atomicI.get());
		System.out.println(System.currentTimeMillis() - start);
	}
	// 068 069 使用CAS实现线程安全计数器 070 071
	private void safeCount() {
		for (;;) {
			int i = atomicI.get();
			boolean suc = atomicI.compareAndSet(i, ++i);
			if (suc) {
				break;
			}
		}
	}
	// 092 093 非线程安全计数器 094 095
	private void count() {
		i++;
	}
}

从Java1.5开始JDK的并发包里提供了一些类来支持原子操作，
如'AtomicBoolean'（用原子方式更新的 boolean 值），
'AtomicInteger'（用原子方式更新的 int 值），
'AtomicLong'（用原子方式更新的 long 值），
这些原子包装类还提供了有用的工具方法，比如'以原子的方式'将当前值'自增1和自减1'。

在'Java并发包'中有一些并发框架'也使用了自旋CAS'的方式来'实现原子操作'，
比如'LinkedTransferQueue类'的'Xfer方法'。CAS虽然很高效的解决原子操作，
但是'CAS'仍然'存在三大问题'。
'ABA问题'，
'循环时间长开销大'，
'只能保证一个共享变量'的'原子操作'。

'ABA问题'。因为'CAS'需要在'操作值的时候''检查'下'值有没有发生变化'，
如果'没有发生变化则更新'，但是如果'一个值原来是A'，'变成了B'，'又变成了A'，
'那么使用CAS进行检查时''会发现它的值没有发生变化'，'但是实际上却变化了'。
ABA问题的'解决思路'就是'使用版本号'。在变量前面追加上版本号，
每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。

从Java1.5开始JDK的'atomic包'里'提供了一个类AtomicStampedReference'来'解决ABA问题'。
这个类的'compareAndSet'方法作用'是'首先'检查当前引用是否等于预期引用'，
并'且当前标志''是否等于''预期标志'，如果'全部相等'，
则'以原子方式''将该引用'和'该标志的值''设置为''给定的更新值'。

public boolean compareAndSet(
	V      expectedReference,// 预期引用
	V      newReference,// 更新后的引用
	int    expectedStamp, // 预期标志
	int    newStamp // 更新后的标志
)

循环时间长开销大。'自旋'CAS如果'长时间不成功'，'会给CPU带来非常大'的'执行开销'。
如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，
'pause指令'有两个作用，
第一它可以'延迟流水线执行指令'（de-pipeline）,使CPU不会消耗过多的执行资源，
延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。

第二它可以'避免在退出循环的时候''因内存顺序冲突'（memory order violation）
而'引起CPU流水线被清空'（CPU pipeline flush），从而'提高CPU的执行效率'。

只能保证一个共享变量的原子操作。当'对一个共享变量'执行'操作时'，
我们'可以使用循环CAS的方式'来'保证原子操作'，但是'对多个共享变量操作时'，
'循环CAS'就'无法保证操作的原子性'，这个时候就'可以用锁'，或者有一个取巧的办法，
就是'把多个共享变量''合并成一个共享变量来操作'。
比如有'两个共享变量i＝2,j=a'，'合并一下ij=2a'，'然后用CAS来操作ij'。
从'Java1.5'开始JDK'提供了AtomicReference'类来'保证引用对象''之间的原子性'，
你'可以把多个变量''放在一个对象里'来'进行CAS操作'。

4.2 '使用锁机制''实现原子操作'
锁机制保证了'只有获得锁的线程''能够操作锁定的内存区域'。
'JVM内部''实现了很多'种'锁机制'，有偏向锁，轻量级锁和互斥锁，
有意思的是'除了偏向锁'，'JVM实现锁的方式都用到的循环CAS'，
当'一个线程'想'进入同步块的时候''使用循环CAS的方式'来'获取锁'，
当它'退出同步块的时候''使用循环CAS释放锁'。
详细说明可以参见文章Java SE1.6中的Synchronized。

